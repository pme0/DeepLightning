task: classification

modes: 
  train: 
  eval: 

data:
  root: null
  dataset: null
  num_workers: 4
  batch_size: 16
  module:
    target: tests.helpers.dummies.DummyDataset
    args:
      length: 5
      size: 8

model:
  module:
    target: tests.helpers.dummies.DummyModel
  network:
    type: null
    args: 
      num_classes: 10
      num_channels: 1
  optimizer:
    target: torch.optim.SGD
    args:
      lr: 0.01
      weight_decay: 0.01
      momentum: 0.9
  scheduler:
    target: torch.optim.lr_scheduler.ExponentialLR
    args:
      gamma: 0.99
    call:
      interval: "epoch"
      frequency: 1
  loss:
    target: torch.nn.CrossEntropyLoss
    args:

engine:
  accelerator: cpu
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 32
  seed: 9999

metrics:
  train: default
  val: default
  test: default

train:
  num_epochs: 1
  val_every_n_epoch: 1
  grad_accum_from_epoch: 0
  grad_accum_every_n_batches: 1
  ckpt_resume_path: null
  ckpt_monitor_metric: null  # used in `ModelCheckpoint` callback
  ckpt_every_n_epochs: 1
  ckpt_save_top_k: 1
  early_stop_metric: null
  early_stop_delta: 0.001
  early_stop_patience: 3

test:
  ckpt_test_path:
  
logger:
  provider: wandb
  project_name: unittests
  tags: ["_"] # cannot be empty
  notes: null
  log_every_n_steps: 20
  runtime:
    run_id: null
    run_name: null
    run_dir: null
    artifact_path: null