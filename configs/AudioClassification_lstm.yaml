modes: 
  train: true
  test: false
  
task: classification
data:
  root: /Users/pme/data/fsd
  dataset: FSD
  num_workers: 4
  batch_size: 256
  module: 
    target: deeplightning.data.dataloaders.audio.fsd.FreeSpokenDigit
  train_transforms:
    normalize: # use `deeplightning.utils.data.compute_dataset_mean_and_stdev()`
      mean: [0.4711]
      stdev: [0.1464]
  test_transforms:
    normalize:
      mean: [0.4711]
      stdev: [0.1464]
 
model:
  module: 
    target: deeplightning.task.audio.audio_classif.AudioClassification
  network:
    target: deeplightning.model.lstm.LSTM
    params: 
      num_classes: .....
      num_channels: .....
  optimizer:
    target: torch.optim.Adadelta
    params:
  scheduler:
    target: torch.optim.lr_scheduler.ExponentialLR
    params:
      gamma: 0.99
    call:
      interval: "epoch"
      frequency: 1
  loss:
    target: torch.nn.CrossEntropyLoss
    params:

engine:
  backend: ddp
  gpus: [0]
  num_nodes: 1
  precision: 32

train:
  num_epochs: 5
  val_every_n_epoch: 1
  grad_accum_from_epoch: 0
  grad_accum_every_n_batches: 1
  ckpt_resume_path: null
  ckpt_every_n_epochs: 1
  early_stop_metric: null
  early_stop_delta: 0.001
  early_stop_patience: 3

test:
  ckpt_test_path: /PATH_TO_CKPT # used only when `modes.test=True`
  
logger:
  log_to_wandb: true
  project_name: AudioClassification_FSD_LSTM
  tags: ["audio", "classification", "lstm"] # cannot be empty
  notes: null
  type: pytorch_lightning.loggers.MLFlowLogger
  params:
    experiment_name: Default
    tracking_uri: mlruns
  log_every_n_steps: 10