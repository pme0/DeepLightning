modes: 
  train: true
  test: false
  
task: ImageClassification

data:
  root: /Users/pme/data/
  dataset: MNIST
  image_size: 28
  num_channels: 1
  num_classes: 10
  num_workers: 4
  batch_size: 256
  module:
    target: deeplightning.data.dataloaders.image.mnist.MNIST

model:
  module:
    target: deeplightning.task.image.classification.TaskModule
  network:
    #target: deeplightning.models.cnn.SymbolCNN
    target: deeplightning.models.mobilenetv3.mobilenet_v3_small 
    params: 
      #num_classes: 10
      #num_channels: 1
      num_classes: 10
      num_channels: 1
  optimizer:
    target: torch.optim.SGD
    params:
      lr: 0.01
      weight_decay: 0.01
      momentum: 0.9
  scheduler:
    target: torch.optim.lr_scheduler.ExponentialLR
    params:
      gamma: 0.99
    call:
      interval: "epoch"
      frequency: 1
  loss:
    target: torch.nn.CrossEntropyLoss
    params:
  
engine:
  accelerator: cpu  # {cpu,gpu}
  strategy: auto    # {auto, ddp, deepspeed}
  devices: 1        # {1, [0,1]}
  num_nodes: 1
  precision: 32

train:
  num_epochs: 1
  val_every_n_epoch: 1
  grad_accum_from_epoch: 0
  grad_accum_every_n_batches: 1
  ckpt_resume_path: null
  ckpt_monitor_metric: val_acc  # used in `ModelCheckpoint` callback
  ckpt_every_n_epochs: 1
  ckpt_save_top_k: 1
  early_stop_metric: null  # used in `EarlyStopping` callback
  early_stop_delta: 0.001
  early_stop_patience: 3

logger:
  name: wandb
  project_name: trial
  tags: ["_"] # cannot be empty
  notes: null
  log_every_n_steps: 20